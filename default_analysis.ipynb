{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# To Default or not to Default\n",
    "### Fred Park\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "My main objective here is to demonstrate how simple it can be to hit the ground running for asking interesting questions against the plethora of datasets available today.\n",
    "\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fredp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Let's begin with some imports...\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.sparse import csr_matrix as sparse_matrix\n",
    "    \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, Normalizer, scale, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we predict if one will default on their credit statements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the UCI default of credit card clients dataset, we find factors like age, education, and income that may be relevant for predicting one's potential for defaulting on their credit.\n",
    "<br>\n",
    "<br>\n",
    "Let's start with some summary statistics:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of defaults: 0.2212\n",
      "\n",
      "Mean balance for non-defaults: 178099.72607430234\n",
      "Median balance for non-defaults: 150000.0\n",
      "\n",
      "Mean balance for defaults: 130109.65641952984\n",
      "Median balance for defaults: 90000.0\n",
      "\n",
      "Average age of people with default payments: 35.72573839662447\n",
      "Median education of people with default payments: 2.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"ccd.xls\")\n",
    "X = data[1:len(data)]\n",
    "n = len(X)\n",
    "\n",
    "print(\"Proportion of defaults: \" + str(X[\"Y\"].sum()/n))\n",
    "print(\"\\nMean balance for non-defaults: \" + str(X[\"X1\"][X[\"Y\"]==0].mean()))\n",
    "print(\"Median balance for non-defaults: \" + str(X[\"X1\"][X[\"Y\"]==0].median()))\n",
    "print(\"\\nMean balance for defaults: \" + str(X[\"X1\"][X[\"Y\"]==1].mean()))\n",
    "print(\"Median balance for defaults: \" + str(X[\"X1\"][X[\"Y\"]==1].median()))\n",
    "\n",
    "X_x = data.loc[:, :'X23'].iloc[1:].astype(float)\n",
    "Y = data.loc[:,'Y'].iloc[1:].astype(float)\n",
    "X_default = X_x[Y==1]\n",
    "X_nondefault = X_x[Y==0]\n",
    "\n",
    "avg_age = X_default.loc[:,'X5'].mean(axis=0)\n",
    "print(\"\\nAverage age of people with default payments:\", avg_age)\n",
    "\n",
    "avg_ed = X_default.loc[:,'X3'].median(axis=0)\n",
    "print(\"Median education of people with default payments:\", avg_ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine some plots for default and non-default payments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some boxes for visualizing average bill amounts for default and non-default payments as a first attempt at gauging spending habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansX =  X_nondefault.loc[:,'X12':'X16'].mean(axis=1);\n",
    "plt.title(\"Average bill amounts for non-defaults\");\n",
    "plt.boxplot(meansX, 0, '');\n",
    "plt.figure();\n",
    "plt.title(\"Average bill amounts for defaults\");\n",
    "plt.boxplot(X_default.loc[:,'X12':'X16'].mean(axis=1), 0, '');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Visualizing age\n",
    "# =====================\n",
    "\n",
    "f, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "\n",
    "# Let's split up the age in decades\n",
    "ages = pd.cut(X['X5'], bins=np.linspace(20,80,7))\n",
    "ages_category = pd.get_dummies(ages)\n",
    "ages_table = pd.concat([X['Y'], ages_category],axis=1)\n",
    "\n",
    "by_age = [ages_category.sum()[x] for x in np.arange(6)]\n",
    "defaults_by_age = [ages_table[ages_table[\"Y\"]==1].sum()[x] for x in np.arange(1,7)]\n",
    "prop_age = np.divide(defaults_by_age,by_age)\n",
    "\n",
    "axs[0].bar([\"20-30\",\"30-40\",\"40-50\",\"50-60\",\"60-70\",\"70-80\"], by_age, 0.3)\n",
    "axs[0].bar([\"20-30\",\"30-40\",\"40-50\",\"50-60\",\"60-70\",\"70-80\"], defaults_by_age, 0.3)\n",
    "axs[0].set_title('Number of defaults by age')\n",
    "axs[0].set_xlabel('Age')\n",
    "axs[0].set_ylabel('Defaults')\n",
    "\n",
    "axs[1].bar([\"20-30\",\"30-40\",\"40-50\",\"50-60\",\"60-70\",\"70-80\"], prop_age, 0.3)\n",
    "axs[1].set_title('Proportion of defaults by age')\n",
    "axs[1].set_xlabel('Age')\n",
    "axs[1].set_ylabel('Proportion of defaults');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "There seems to be an upward trend in the data with defaults as one gets older, with the exception of those aged 20-29 - perhaps indulging in their transition to adulthood?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legend\n",
    "\n",
    "- Gender (1 = male; 2 = female). \n",
    "- Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "- Marital status (1 = married; 2 = single; 3 = others). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Visualizing education\n",
    "# ======================\n",
    "\n",
    "f, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "\n",
    "ed = list(X[\"X3\"].value_counts(sort=False))\n",
    "defaults_by_ed = list(X[\"X3\"][X[\"Y\"]==1].value_counts(sort=False))\n",
    "defaults_by_ed.insert(0,0)\n",
    "prop_ed = np.divide(defaults_by_ed,ed)\n",
    "\n",
    "axs[0].bar(np.arange(7),ed,width=0.5)\n",
    "axs[0].bar(np.arange(7),defaults_by_ed,width=0.5)\n",
    "axs[0].set_title('Proportion of defaults by education')\n",
    "axs[0].set_xlabel('Education')\n",
    "axs[0].set_ylabel('Proportion of defaults')\n",
    "\n",
    "axs[1].bar(np.arange(7),prop_ed,width=0.5)\n",
    "axs[1].set_title('Proportion of defaults by education')\n",
    "axs[1].set_xlabel('Education')\n",
    "axs[1].set_ylabel('Proportion of defaults');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "It seems that with higher levels of education, the proportion of defaults\n",
    "slowly decrease.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Proportion of defaults for gender & education\n",
    "# ======================\n",
    "\n",
    "f, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "\n",
    "education_martial_defaults = X[[\"X2\",\"X3\"]][X[\"Y\"]==1].groupby([\"X2\",\"X3\"]).size()\n",
    "education_martial = X[[\"X2\",\"X3\"]].groupby([\"X2\",\"X3\"]).size()\n",
    "education_martial_prop =education_martial_defaults/education_martial\n",
    "education_martial_prop[~education_martial_prop.isnull()].plot(kind=\"bar\", ax=axs[0])\n",
    "axs[0].set_title('Proportion of defaults by gender and education')\n",
    "axs[0].set_xlabel('Gender & Education')\n",
    "axs[0].set_ylabel('Proportion of defaults');\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Proportion of defaults for gender & martial status\n",
    "# ======================\n",
    "\n",
    "education_martial_defaults = X[[\"X2\",\"X4\"]][X[\"Y\"]==1].groupby([\"X2\",\"X4\"]).size()\n",
    "education_martial = X[[\"X2\",\"X4\"]].groupby([\"X2\",\"X4\"]).size()\n",
    "education_martial_prop =education_martial_defaults/education_martial\n",
    "education_martial_prop[~education_martial_prop.isnull()].plot(kind=\"bar\", ax=axs[1])\n",
    "axs[1].set_title('Proportion of defaults by gender and martial status')\n",
    "axs[1].set_xlabel('Gender & Martial Status')\n",
    "axs[1].set_ylabel('Proportion of defaults');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Plotting gender with education gives us an expected downward trend of lowering default rates as one gets more school. However, a higher proportion of men seem to default than women.\n",
    "\n",
    "\n",
    "And among the 4 combinations of Male/Woman and Single/Married:\n",
    "- Married men have the highest proportion of defaults\n",
    "- Single women have the lowest proportion of defaults\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "## Predictions\n",
    "\n",
    "\n",
    "Now for some ***predictions*** - first, we'll read in the data and chop it up into train/validation/test sets. Validation error is a popular metric for seeing how well we do with our models - here, it approximately measures how well the model does in predicting if someone will default or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_excel(\"../data/ccd.xls\")\n",
    "X = X[1:len(X)] # remove column labels\n",
    "\n",
    "n = len(X)\n",
    "n_col = len(X.columns)\n",
    "x = X.iloc[0:n,0:n_col-1]\n",
    "y = X[\"Y\"][0:n]\n",
    "\n",
    "# divide into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=27)\n",
    "\n",
    "# divide train into train/valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=27)\n",
    "\n",
    "# matrixify\n",
    "X_train = X_train.astype(float).as_matrix()\n",
    "y_train = y_train.astype(float).as_matrix()\n",
    "X_valid = X_valid.astype(float).as_matrix()\n",
    "y_valid = y_valid.astype(float).as_matrix()\n",
    "X_test = X_test.astype(float).as_matrix()\n",
    "y_test = y_test.astype(float).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L2-Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's begin using logistic regression with L2-regularization and see how well it does with varying regularization strengths (strong to weak).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# =============== Logistic Regression ========================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_c = 0\n",
    "best_err_so_far = 1\n",
    "C = [0.000001, 0.001, 0.1, 0.5, 1, 1.5, 2, 5, 20, 100]\n",
    "v_errors = np.zeros(len(C))\n",
    "for i, j in enumerate(C):\n",
    "    model = LogisticRegression(penalty='l2', solver='lbfgs', C=j)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    te_error = 1-accuracy_score(y_valid.ravel(),y_pred)\n",
    "    v_errors[i] = te_error\n",
    "    if te_error < best_err_so_far:\n",
    "        best_c = j\n",
    "        best_err_so_far = te_error\n",
    "\n",
    "print(\"Best C: \" + str(best_c))\n",
    "print(\"Validation error: %.3f\" % best_err_so_far)\n",
    "\n",
    "\n",
    "# Best results: \n",
    "# =================================\n",
    "# Best C: 0.5\n",
    "# Validation error: 0.218"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1-Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Logistic Regression ========================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_c = 0\n",
    "best_err_so_far = 1\n",
    "C = [0.000001, 0.001, 0.1, 0.5, 1, 1.5, 2, 5, 20, 100]\n",
    "v_errors = np.zeros(len(C))\n",
    "for i, j in enumerate(C):\n",
    "    model = LogisticRegression(penalty='l1', C=j)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    te_error = 1-accuracy_score(y_valid.ravel(),y_pred)\n",
    "    v_errors[i] = te_error\n",
    "    if te_error < best_err_so_far:\n",
    "        best_c = j\n",
    "        best_err_so_far = te_error\n",
    "\n",
    "print(\"Best C: \" + str(best_c))\n",
    "print(\"Validation error: %.3f\" % best_err_so_far)\n",
    "\n",
    "\n",
    "# Best results: \n",
    "# =================================\n",
    "# Best C: 100\n",
    "# Validation error: 0.186"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Next we look at how well KNN performs - because there are so many examples, we can search for larger values of k to avoid overfitting. We optimize for this number of neighbors and the different metrics of KNN to measure which is the best way to score distance between points, using k-fold cross validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== KNN ========================\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n = len(X_train)\n",
    "\n",
    "best_so_far = 1\n",
    "best_i = 0\n",
    "best_metric = \"\"\n",
    "metrics = [\"euclidean\",\"manhattan\",\"chebyshev\",\"minkowski\",\"hamming\",\"canberra\",\"braycurtis\"]\n",
    "for j in metrics:\n",
    "    inner_so_far = 1\n",
    "    inner_best_i = 0\n",
    "    for i in np.arange(50,100):\n",
    "        for z in range(10):\n",
    "            begin = int(z * n / 10)\n",
    "            end = int((z + 1) * n / 10)\n",
    "\n",
    "            Xvalid = X_train[begin:end]\n",
    "            yvalid = y_train[begin:end]\n",
    "            \n",
    "            Xtrain = np.append(X_train[:begin,:], X_train[end:,:], axis=0)\n",
    "            ytrain = np.append(y_train[:begin], y_train[end:], axis=0)\n",
    "            model = KNeighborsClassifier(i, metric=j)\n",
    "            \n",
    "            model.fit(Xtrain, ytrain)\n",
    "            y_pred = model.predict(Xvalid)\n",
    "            v_error = np.mean(y_pred != yvalid)\n",
    "            if (v_error < inner_so_far):\n",
    "                inner_best_i = i\n",
    "                inner_so_far = v_error\n",
    "    if (inner_so_far < best_so_far):\n",
    "        best_so_far = inner_so_far\n",
    "        best_i = inner_best_i\n",
    "        best_metric = j\n",
    "    print(\"Metric: \" + j)\n",
    "    print(\"Best K: \" + str(inner_best_i))\n",
    "    print(\"Validation error: %.3f\" % inner_so_far)\n",
    "\n",
    "print(\"Metric: \" + best_metric)\n",
    "print(\"Best K: \" + str(best_i))\n",
    "print(\"Validation error: %.3f\" % best_so_far)\n",
    "\n",
    "\n",
    "# Best results:\n",
    "# ==================\n",
    "# Metric: hamming\n",
    "# Best K: 59\n",
    "# Validation error: 0.181\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Test on validation set\n",
    "# =========================\n",
    "model = KNeighborsClassifier(59, metric=\"hamming\")\n",
    "model.fit(X_train, y_train)            \n",
    "y_pred = model.predict(X_valid)\n",
    "te_error = np.mean(y_pred != y_valid)\n",
    "print(\"Validation error: \" + str(te_error))\n",
    "\n",
    "# Validation error: 0.18895833333333334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We now examine using a neural network, scikit's MLPClassifier, to predict defaults. We optimize for multiple combinations of hidden layer sizes, as well as varying alpha and taking the mode of the best set of these hyperparameters. Instead of using cross validation, we take the mode of the best set of hyperparameters based on a range of different initializations.\n",
    "\n",
    "*Note that we could use grid-search here (also available from scikit's library) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Neural Net ========================\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "best_layer_size_res = []\n",
    "best_alpha_res = []\n",
    "\n",
    "\n",
    "inner_best_layer_size = 0\n",
    "inner_best_alpha = 0\n",
    "inner_best_error = 1\n",
    "\n",
    "hidden_layers = [(100, 100, 10), (300,100,10), (200,100,100,100), (100,100,10,10,10),\n",
    "                (100,10,10), (100,100,10,10), (50,20,20,10)]\n",
    "alpha = [0.000001,  0.00001, 0.0005, 0.0001, 0.001,  0.01, 0.1, 1]\n",
    "seeds = [1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "\n",
    "for s in seeds:\n",
    "\tinner_best_layer_size = 0\n",
    "\tinner_best_alpha = 0\n",
    "\tinner_best_error = 1\n",
    "\tfor i in hidden_layers:\n",
    "\t\terror_so_far = 1\n",
    "\t\tinner_alpha = 1\n",
    "\t\tfor j in alpha:\n",
    "\t\t\tmodel = MLPClassifier(hidden_layer_sizes=i, random_state=s, alpha=j)\n",
    "\t\t\tmodel.fit(X_train, y_train)\n",
    "\t\t\ty_pred = model.predict(X_valid)\n",
    "\t\t\tte_error = np.mean(y_pred != y_valid)\n",
    "\t\t\tif te_error < error_so_far:\n",
    "\t\t\t\terror_so_far = te_error\n",
    "\t\t\t\tinner_alpha = j\n",
    "\t\tif error_so_far < inner_best_error:\n",
    "\t\t\tinner_best_layer_size = i\n",
    "\t\t\tinner_best_alpha = inner_alpha\n",
    "\t\t\tinner_best_error = error_so_far\n",
    "\tbest_layer_size_res.append(inner_best_layer_size)\n",
    "\tbest_alpha_res.append(inner_best_alpha)\n",
    "\tprint(\"Seed: \" + str(s))\n",
    "\tprint(\"Best layer size: \" + str(inner_best_layer_size))\n",
    "\tprint(\"Best alpha: \" + str(inner_best_alpha))\n",
    "\tprint(\"Best test error: %.3f\" % inner_best_error)\n",
    "\tprint(\"=========================\")\n",
    "\n",
    "hidden_layer_size_mode = max(set(best_layer_size_res), key=best_layer_size_res.count)\n",
    "print(\"Best hidden layer size (mode): \" + str(hidden_layer_size_mode))\n",
    "print(\"Using alpha: \" + str(best_alpha_res[best_layer_size_res.index(hidden_layer_size_mode)]))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Best hidden layer size (mode): (100, 100, 10, 10, 10)\n",
    "# Alpha: 1e-06\n",
    "# Validation error = 0.217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we examine decision trees. Optimizing over different minimum number of samples required to split as well as the depth of the tree, we take advantage of k-fold cross validation to better gauge our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Decision Tree ========================\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "n = len(X_train)\n",
    "\n",
    "best_depth = 1\n",
    "best_split = 2\n",
    "best_error = 1\n",
    "depths = np.arange(1,30)\n",
    "\n",
    "for j in [2, 30, 300, 500, 750, 1000, 3000]:\n",
    "    for i, max_depth in enumerate(depths):\n",
    "        for z in range(10):\n",
    "            begin = int(z * n / 10)\n",
    "            end = int((z + 1) * n / 10)\n",
    "\n",
    "            Xvalid = X_train[begin:end]\n",
    "            yvalid = y_train[begin:end]\n",
    "            \n",
    "            Xtrain = np.append(X_train[:begin,:], X_train[end:,:], axis=0)\n",
    "            ytrain = np.append(y_train[:begin], y_train[end:], axis=0)\n",
    "\n",
    "            model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=j, criterion='entropy', random_state=27)\n",
    "            model.fit(Xtrain, ytrain)\n",
    "            y_pred = model.predict(Xvalid)\n",
    "            te_error = np.mean(y_pred != yvalid)\n",
    "            if te_error < best_error:\n",
    "                best_error = te_error\n",
    "                best_split = j\n",
    "                best_depth = max_depth\n",
    "\n",
    "print(\"=================================\")\n",
    "print(\"Results: \")\n",
    "print(\"Validation error: %.3f\" % te_error)\n",
    "print(\"Depth: \" + str(best_depth))\n",
    "print(\"Best num to split: \" + str(best_split))\n",
    "\n",
    "# =========================\n",
    "# Results:\n",
    "# Validation error: 0.178\n",
    "# Depth: 9\n",
    "# Best num to split: 300\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Test on validation set\n",
    "# =========================\n",
    "model = DecisionTreeClassifier(max_depth=9, min_samples_split=300, criterion='entropy', random_state=27)\n",
    "model.fit(X_train, y_train)            \n",
    "y_pred = model.predict(X_valid)\n",
    "te_error = np.mean(y_pred != y_valid)\n",
    "print(\"Validation error: \" + str(te_error))\n",
    "\n",
    "# Validation error: 0.18333333333333332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more model exploration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Nets Logistic \n",
    "nnModel = MLPClassifier(activation='logistic').fit(X_train, y_train)\n",
    "y_hat = nnModel.predict(X_train)\n",
    "print(\"\\nLogistic neural net validation error:\", 1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "# Neural Nets Relu\n",
    "nnModelr = MLPClassifier().fit(X_train, y_train)\n",
    "y_hat = nnModelr.predict(X_train)\n",
    "print(\"\\nRelu neural net validation error:\", 1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "# Random Forest\n",
    "rfModel = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_hat = rfModel.predict(X_train)\n",
    "print(\"\\nRandom forest validation error:\", 1-accuracy_score(y_train.ravel(),y_hat))\n",
    "print(\"* Best so far!\")\n",
    "\n",
    "# Linear SVC\n",
    "svcModel = LinearSVC().fit(X_train, y_train)\n",
    "y_hat = svcModel.predict(X_train)\n",
    "print(\"\\nLinear SVC validation error:\", 1 - accuracy_score(y_train.ravel(),y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Feature Exploration\n",
    "\n",
    "Next we will explore some feature transformations and selections - dabbling in change of basis, normalizing, and scaling of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# Logistic Regression with L2 Regularization\n",
    "print(\"\\nPolynomial Logistic L2 classifier validation error with c = 0.1, deg=2\")\n",
    "l2Model = LogisticRegression(penalty='l2', solver='lbfgs', C=0.1).fit(X_poly, y_train)\n",
    "y_hat = l2Model.predict(X_poly)\n",
    "print(1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "# # Logistic Regression with L1 Regularization\n",
    "# print(\"Polynomial Logistic L1 classifier validation error with c = 0.1, deg=2\")\n",
    "# l1Model = LogisticRegression(penalty='l1', C=0.1).fit(X_poly, y_train)\n",
    "# y_hat = l1Model.predict(X_poly)\n",
    "# print(1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# Logistic Regression with L2 Regularization\n",
    "print(\"\\nPolynomial Logistic L2 classifier validation error with c = 0.1, deg=3\")\n",
    "l2Model = LogisticRegression(penalty='l2', solver='lbfgs', C=0.1).fit(X_poly, y_train)\n",
    "y_hat = l2Model.predict(X_poly)\n",
    "print(1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "# # Logistic Regression with L1 Regularization\n",
    "# print(\"Polynomial Logistic L1 classifier validation error with c = 0.1, deg=3\")\n",
    "# l1Model = LogisticRegression(penalty='l1', C=0.1).fit(X_poly, y_train)\n",
    "# y_hat = l1Model.predict(X_poly)\n",
    "# print(1-accuracy_score(y_train.ravel(),y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Data\n",
    "normalizer = Normalizer().fit(X)\n",
    "X_normal = normalizer.transform(X_train)\n",
    "\n",
    "# Logistic Regression with L2 Regularization\n",
    "print(\"\\nNormalized Logistic L2 classifier validation error with c = 0.1\")\n",
    "l2Model = LogisticRegression(penalty='l2', solver='lbfgs', C=0.1).fit(X_normal, y_train)\n",
    "y_hat = l2Model.predict(X_normal)\n",
    "print(1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "# Logistic Regression with L1 Regularization\n",
    "print(\"Normalized Logistic L1 classifier validation error with\t c = 0.1\")\n",
    "l1Model = LogisticRegression(penalty='l1', C=0.1).fit(X_normal, y_train)\n",
    "y_hat = l1Model.predict(X_normal)\n",
    "print(1-accuracy_score(y_train.ravel(),y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X_train)\n",
    "\n",
    "# Logistic Regression with L2 Regularization\n",
    "print(\"\\nStandard Scaler Logistic L2 classifier validation error with c = 0.1\")\n",
    "l2Model = LogisticRegression(penalty='l2', solver='lbfgs', C=0.1).fit(X_scaler, y_train)\n",
    "y_hat = l2Model.predict(X_scaler)\n",
    "print(1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "# Logistic Regression with L1 Regularization\n",
    "print(\"\\nStandard Scaler Logistic L1 classifier validation error with c = 0.1\")\n",
    "l1Model = LogisticRegression(penalty='l1', C=0.1).fit(X_scaler, y_train)\n",
    "y_hat = l1Model.predict(X_scaler)\n",
    "print(1-accuracy_score(y_train.ravel(),y_hat))\n",
    "\n",
    "print(\"\\nStandard Scaler KNN validation error with k = 0.59, using hamming distance\")\n",
    "model = KNeighborsClassifier(59, metric=\"hamming\")\n",
    "model.fit(X_scaler, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "te_error = np.mean(y_pred != y_valid)\n",
    "print(\"Validation error: \" + str(te_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature addition and selection\n",
    "\n",
    "We add two new features:\n",
    "1. Payment rate: computed by Monthly Bill statement / Amount paid that month\n",
    "    - This could be insightful as higher proportions of bill payments can indicate they are on a good track\n",
    "2. Number of paid months\n",
    "    - More consistent payments with each statement might indicate that the person has a stable income, and thus avoid defaulting\n",
    "    \n",
    "Additionally, we use one-hot encoding to binarize our categorial features (age, education, gender, marital status)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_excel(\"../data/ccd.xls\")\n",
    "X = X[1:len(X)] # remove column labels\n",
    "\n",
    "\n",
    "# New feature: payment rate (Monthly Bill statement / Amount paid that month)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "bill_amt = X.iloc[:,11:17].astype('float64').as_matrix()\n",
    "pay_amt = X.iloc[:,17:23].astype('float64').as_matrix()\n",
    "prop_paid = pay_amt/bill_amt\n",
    "pay_rate = [prop_paid[i].sum()/np.count_nonzero(prop_paid[i]) for i in np.arange(len(prop_paid))]\n",
    "pay_rate = pd.DataFrame(np.nan_to_num(pay_rate))\n",
    "# ceiling for outliers\n",
    "pay_rate[pay_rate >= 10] = 10\n",
    "pay_rate[pay_rate <= -10] = -10\n",
    "X.insert(23, \"X24\", pay_rate)\n",
    "X.iat[29999,23] = 0 # remove NaN\n",
    "\n",
    "# New feature: # of paid months\n",
    "non_zeros = [np.count_nonzero(i) for i in pay_amt]\n",
    "nz = pd.DataFrame(np.nan_to_num(non_zeros))[0]\n",
    "X.insert(24, \"X25\", nz)\n",
    "X.iat[29999,24] = 0 # remove NaN\n",
    "\n",
    "n = len(X)\n",
    "n_col = len(X.columns)\n",
    "x = X.iloc[0:n,0:n_col-1]\n",
    "\n",
    "# Split gender into columns\n",
    "gender = pd.cut(X['X2'], bins=[0,1,2])\n",
    "gender_cols = pd.get_dummies(gender)\n",
    "x.drop(['X2'], axis=1, inplace=True)\n",
    "x = pd.concat([x, gender_cols],axis=1)\n",
    "\n",
    "# Split education into columns\n",
    "educ = pd.cut(X['X3'], bins=[0,1,2,3,4,5,6])\n",
    "educ_cols = pd.get_dummies(educ)\n",
    "x.drop(['X3'], axis=1, inplace=True)\n",
    "x = pd.concat([x, educ_cols],axis=1)\n",
    "\n",
    "# Split martial status into columns\n",
    "martial = pd.cut(X['X4'], bins=[0,1,2,3])\n",
    "martial_cols = pd.get_dummies(martial)\n",
    "x.drop(['X4'], axis=1, inplace=True)\n",
    "x = pd.concat([x, martial_cols],axis=1)\n",
    "\n",
    "# Split age into columns\n",
    "ages = pd.cut(X['X5'], bins=np.linspace(20,80,7))\n",
    "ages_cat = pd.get_dummies(ages)\n",
    "x.drop(['X5'], axis=1, inplace=True)\n",
    "x = pd.concat([x, ages_cat],axis=1)\n",
    "\n",
    "y = X[\"Y\"][0:n]\n",
    "# divide into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=27)\n",
    "# divide train into train/valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=27)\n",
    "\n",
    "# matrixify\n",
    "X_train = X_train.astype(float).as_matrix()\n",
    "y_train = y_train.astype(float).as_matrix()\n",
    "X_valid = X_valid.astype(float).as_matrix()\n",
    "y_valid = y_valid.astype(float).as_matrix()\n",
    "X_test = X_test.astype(float).as_matrix()\n",
    "y_test = y_test.astype(float).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Using decision trees below on our new transformed dataset, we get a better validation error than before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "n = len(X_train)\n",
    "print(\"starting..\")\n",
    "\n",
    "best_depth = 1\n",
    "best_split = 2\n",
    "best_error = 1\n",
    "depths = np.arange(1,30)\n",
    "\n",
    "for j in [2, 30, 300, 500, 750, 1000, 3000]:\n",
    "    for i, max_depth in enumerate(depths):\n",
    "        for z in range(10):\n",
    "            begin = int(z * n / 10)\n",
    "            end = int((z + 1) * n / 10)\n",
    "\n",
    "            Xvalid = X_train[begin:end]\n",
    "            yvalid = y_train[begin:end]\n",
    "            \n",
    "            Xtrain = np.append(X_train[:begin,:], X_train[end:,:], axis=0)\n",
    "            ytrain = np.append(y_train[:begin], y_train[end:], axis=0)\n",
    "\n",
    "            model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=j, criterion='entropy', random_state=27)\n",
    "            model.fit(Xtrain, ytrain)\n",
    "            y_pred = model.predict(Xvalid)\n",
    "            te_error = np.mean(y_pred != yvalid)\n",
    "            if te_error < best_error:\n",
    "                best_error = te_error\n",
    "                best_split = j\n",
    "                best_depth = max_depth\n",
    "print(\"=================================\")\n",
    "print(\"Results: \")\n",
    "print(\"Validation error: %.3f\" % te_error)\n",
    "print(\"Depth: \" + str(best_depth))\n",
    "print(\"Best num to split: \" + str(best_split))\n",
    "\n",
    "\n",
    "# =================================\n",
    "# Results: \n",
    "# Validation error: 0.178\n",
    "# Depth: 7\n",
    "# Best num to split: 300\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Test on validation set\n",
    "# =========================\n",
    "model = DecisionTreeClassifier(max_depth=7, min_samples_split=300, criterion='entropy', random_state=27)\n",
    "model.fit(X_train, y_train)            \n",
    "y_pred = model.predict(X_valid)\n",
    "te_error = np.mean(y_pred != y_valid)\n",
    "print(\"Validation test error: \" + str(te_error))\n",
    "\n",
    "# Improvement!\n",
    "\n",
    "# Validation test error: 0.18145833333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tallest tree of all\n",
    "\n",
    "The above demonstrates that decision trees do better on our new transformed dataset. Thus, we will optimize a random forest and perform feature selection to gain confidence in our new features.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Optimization - #6 depth, 10 features - 0.140, 100 estimates\n",
    "parameters = {'max_features':[1,6,15,23], 'max_depth':[1,10,50,100,140,200],'n_estimators':[40,50,100,200,300]}\n",
    "rfModel = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(rfModel, parameters)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "y_hat = gridsearch.predict(X_valid)\n",
    "print(\"\\nOptimized Random forest validation error:\", 1-accuracy_score(y_valid.ravel(),y_hat))\n",
    "print(\"Parameters:\", gridsearch.best_params_ )\n",
    "\n",
    "# Random Forest Feature Selection \n",
    "# Relevant Features In Order of Relevance: 6,5,1,12,23,15,13,14,17,16\n",
    "extras = ExtraTreesClassifier().fit(X_train, y_train)\n",
    "model = SelectFromModel(extras, prefit=True)\n",
    "X_train_new = model.transform(X_train)\n",
    "std = np.std([extras.feature_importances_ for tree in extras.estimators_], axis=0)\n",
    "indices = np.argsort(extras.feature_importances_)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_train_new.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], extras.feature_importances_[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The optimal set of parameters for our random forest is depth 7 with 23 features. We can also confirm that our new features are also selected for in our selection analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Predicting on the test set\n",
    "\n",
    "Finally, running our best model (random forest) with our discovered hyperparameters on the test set...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model =Random Forest\n",
    "rfModel = RandomForestClassifier(max_depth=7, n_estimators=100, max_features=23, random_state=27).fit(X_train, y_train)\n",
    "y_pred = rfModel.predict(X_valid)\n",
    "print(\"\\nRandom forest validation error:\", 1-accuracy_score(y_valid.ravel(), y_pred))\n",
    "\n",
    "X = np.concatenate((X_train, X_valid))\n",
    "y = np.concatenate((y_train, y_valid))\n",
    "\n",
    "# Best model =Random Forest\n",
    "rfModel = RandomForestClassifier(max_depth=7, n_estimators=100, max_features=23, random_state=27).fit(X, y)\n",
    "y_pred = rfModel.predict(X_test)\n",
    "print(\"\\nRandom forest test error:\", 1-accuracy_score(y_test.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "From what we've done so far, we see that the variance across all the different models is rather dense. This can be both encouraging and discouraging depending on how you look at the problem - nonetheless, I hope this was a good taster into the world of machine learning! \n",
    "\n",
    "If you have any questions, feel free to email me at fred.park9841@hotmail.com!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
